{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":97919,"databundleVersionId":11872932,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchaudio transformers librosa scikit-learn xgboost --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:38:52.760226Z","iopub.execute_input":"2025-05-02T18:38:52.760401Z","iopub.status.idle":"2025-05-02T18:40:11.535702Z","shell.execute_reply.started":"2025-05-02T18:38:52.760383Z","shell.execute_reply":"2025-05-02T18:40:11.534818Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nimport torchaudio\nimport librosa\nimport pandas as pd\nimport numpy as np\nfrom torch import nn\nfrom tqdm import tqdm\nfrom transformers import Wav2Vec2Model, Wav2Vec2Processor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom torch.utils.data import Dataset, DataLoader\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:02:41.012396Z","iopub.execute_input":"2025-05-02T19:02:41.013000Z","iopub.status.idle":"2025-05-02T19:02:41.017766Z","shell.execute_reply.started":"2025-05-02T19:02:41.012978Z","shell.execute_reply":"2025-05-02T19:02:41.017143Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/shl-intern-hiring-assessment/Dataset/train.csv')\ntest_df = pd.read_csv('/kaggle/input/shl-intern-hiring-assessment/Dataset/test.csv')\n\ntrain_path = \"/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train\"\ntest_path = \"/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:46:27.913508Z","iopub.execute_input":"2025-05-02T18:46:27.914425Z","iopub.status.idle":"2025-05-02T18:46:27.934000Z","shell.execute_reply.started":"2025-05-02T18:46:27.914397Z","shell.execute_reply":"2025-05-02T18:46:27.933262Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\nmodel = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\").to(device)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:46:35.520675Z","iopub.execute_input":"2025-05-02T18:46:35.520971Z","iopub.status.idle":"2025-05-02T18:46:39.139516Z","shell.execute_reply.started":"2025-05-02T18:46:35.520950Z","shell.execute_reply":"2025-05-02T18:46:39.138813Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef48b556a9854317bdbb2abe57f8256f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efd80c2c32e64c5ea2fe504c6705815e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3173e0f080294cffb6185ea2a2a28d2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb7453a53dc8462191d3ff172f158f12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc54e0cac56a42b19f4c54d101100f90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a4c62e557c44edf825c113eb80076bd"}},"metadata":{}},{"name":"stderr","text":"Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Wav2Vec2Model(\n  (feature_extractor): Wav2Vec2FeatureEncoder(\n    (conv_layers): ModuleList(\n      (0): Wav2Vec2GroupNormConvLayer(\n        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n        (activation): GELUActivation()\n        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n      )\n      (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n        (activation): GELUActivation()\n      )\n      (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n        (activation): GELUActivation()\n      )\n    )\n  )\n  (feature_projection): Wav2Vec2FeatureProjection(\n    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (projection): Linear(in_features=512, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): Wav2Vec2Encoder(\n    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n      (conv): ParametrizedConv1d(\n        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n        (parametrizations): ModuleDict(\n          (weight): ParametrizationList(\n            (0): _WeightNorm()\n          )\n        )\n      )\n      (padding): Wav2Vec2SamePadLayer()\n      (activation): GELUActivation()\n    )\n    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (layers): ModuleList(\n      (0-11): 12 x Wav2Vec2EncoderLayer(\n        (attention): Wav2Vec2SdpaAttention(\n          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.1, inplace=False)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (feed_forward): Wav2Vec2FeedForward(\n          (intermediate_dropout): Dropout(p=0.1, inplace=False)\n          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n          (output_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def extract_wav2vec2_features(file_path):\n    try:\n        waveform, sr = torchaudio.load(file_path)\n        waveform = waveform.squeeze(0)\n\n        if sr != 16000:\n            waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n\n        inputs = processor(waveform, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n        with torch.no_grad():\n            outputs = model(**inputs.to(device))\n        hidden_states = outputs.last_hidden_state.squeeze(0).cpu().numpy()\n\n        # Mean pooling across time\n        feature_vector = np.mean(hidden_states, axis=0)\n        return feature_vector\n    except Exception as e:\n        print(\"Error:\", file_path)\n        return np.zeros(768)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:47:13.577478Z","iopub.execute_input":"2025-05-02T18:47:13.578047Z","iopub.status.idle":"2025-05-02T18:47:13.583942Z","shell.execute_reply.started":"2025-05-02T18:47:13.578021Z","shell.execute_reply":"2025-05-02T18:47:13.582979Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"X = []\ny = []\nfor i, row in tqdm(train_df.iterrows(), total=len(train_df)):\n    file_path = os.path.join(train_path, row['filename'])\n    feat = extract_wav2vec2_features(file_path)\n    X.append(feat)\n    y.append(row['label'])\n\nX = np.array(X)\ny = np.array(y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:47:34.397446Z","iopub.execute_input":"2025-05-02T18:47:34.398203Z","iopub.status.idle":"2025-05-02T18:53:51.182295Z","shell.execute_reply.started":"2025-05-02T18:47:34.398166Z","shell.execute_reply":"2025-05-02T18:53:51.181572Z"}},"outputs":[{"name":"stderr","text":" 28%|██▊       | 124/444 [01:06<02:29,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Error: /kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1159.wav\n","output_type":"stream"},{"name":"stderr","text":" 40%|███▉      | 177/444 [01:47<02:13,  1.99it/s]","output_type":"stream"},{"name":"stdout","text":"Error: /kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_58.wav\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▍   | 287/444 [03:21<01:46,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Error: /kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_252.wav\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 444/444 [06:16<00:00,  1.18it/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:54:15.159360Z","iopub.execute_input":"2025-05-02T18:54:15.160009Z","iopub.status.idle":"2025-05-02T18:54:15.168456Z","shell.execute_reply.started":"2025-05-02T18:54:15.159966Z","shell.execute_reply":"2025-05-02T18:54:15.167553Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model_xgb = XGBRegressor(n_estimators=150, learning_rate=0.1, max_depth=6, random_state=42)\nmodel_xgb.fit(X_train, y_train)\n\ntrain_preds = model_xgb.predict(X_train)\nval_preds = model_xgb.predict(X_val)\n\ntrain_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\nval_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n\nprint(f\"Train RMSE: {train_rmse:.4f}\")\nprint(f\"Validation RMSE: {val_rmse:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:54:21.762607Z","iopub.execute_input":"2025-05-02T18:54:21.763522Z","iopub.status.idle":"2025-05-02T18:54:35.346375Z","shell.execute_reply.started":"2025-05-02T18:54:21.763485Z","shell.execute_reply":"2025-05-02T18:54:35.345389Z"}},"outputs":[{"name":"stdout","text":"Train RMSE: 0.0421\nValidation RMSE: 0.8052\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"X_test = []\nfile_names = []\n\nfor i, row in tqdm(test_df.iterrows(), total=len(test_df)):\n    file_path = os.path.join(test_path, row['filename'])\n    feat = extract_wav2vec2_features(file_path)\n    X_test.append(feat)\n    file_names.append(row['filename'])\n\nX_test = np.array(X_test)\ntest_preds = model_xgb.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T18:55:22.802111Z","iopub.execute_input":"2025-05-02T18:55:22.802475Z","iopub.status.idle":"2025-05-02T18:58:02.610324Z","shell.execute_reply.started":"2025-05-02T18:55:22.802448Z","shell.execute_reply":"2025-05-02T18:58:02.609512Z"}},"outputs":[{"name":"stderr","text":" 55%|█████▍    | 112/204 [01:17<00:44,  2.07it/s]","output_type":"stream"},{"name":"stdout","text":"Error: /kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_988.wav\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 126/204 [01:28<00:39,  1.98it/s]","output_type":"stream"},{"name":"stdout","text":"Error: /kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_41.wav\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 204/204 [02:39<00:00,  1.28it/s]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'filename': file_names,\n    'label': test_preds\n})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:00:14.759521Z","iopub.execute_input":"2025-05-02T19:00:14.759865Z","iopub.status.idle":"2025-05-02T19:00:14.766978Z","shell.execute_reply.started":"2025-05-02T19:00:14.759840Z","shell.execute_reply":"2025-05-02T19:00:14.766120Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"**Method-2**","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:03:06.799211Z","iopub.execute_input":"2025-05-02T19:03:06.800036Z","iopub.status.idle":"2025-05-02T19:03:06.804112Z","shell.execute_reply.started":"2025-05-02T19:03:06.800009Z","shell.execute_reply":"2025-05-02T19:03:06.803333Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:03:10.851901Z","iopub.execute_input":"2025-05-02T19:03:10.852693Z","iopub.status.idle":"2025-05-02T19:03:10.859514Z","shell.execute_reply.started":"2025-05-02T19:03:10.852655Z","shell.execute_reply":"2025-05-02T19:03:10.858610Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/shl-intern-hiring-assessment/Dataset/train.csv')\nAUDIO_DIR = '/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:03:37.665352Z","iopub.execute_input":"2025-05-02T19:03:37.665672Z","iopub.status.idle":"2025-05-02T19:03:37.674686Z","shell.execute_reply.started":"2025-05-02T19:03:37.665636Z","shell.execute_reply":"2025-05-02T19:03:37.674003Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\nwav2vec = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\").to(device)\nwav2vec.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:03:44.386085Z","iopub.execute_input":"2025-05-02T19:03:44.386387Z","iopub.status.idle":"2025-05-02T19:03:47.614904Z","shell.execute_reply.started":"2025-05-02T19:03:44.386364Z","shell.execute_reply":"2025-05-02T19:03:47.614029Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea9633b277845b1aa160cf48d9901f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d38328024584e86a06affe958adecac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.84k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e88222a8ff41a7b593cb21ee8f120b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8488cb2e117448f9eb0f9426b0e44f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5d2dbb365cc4df1a519ec530cc7e2fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/380M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41a388a439594033b260e48cd47094c7"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Wav2Vec2Model(\n  (feature_extractor): Wav2Vec2FeatureEncoder(\n    (conv_layers): ModuleList(\n      (0): Wav2Vec2GroupNormConvLayer(\n        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n        (activation): GELUActivation()\n        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n      )\n      (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n        (activation): GELUActivation()\n      )\n      (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n        (activation): GELUActivation()\n      )\n    )\n  )\n  (feature_projection): Wav2Vec2FeatureProjection(\n    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (projection): Linear(in_features=512, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): Wav2Vec2Encoder(\n    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n      (conv): ParametrizedConv1d(\n        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n        (parametrizations): ModuleDict(\n          (weight): ParametrizationList(\n            (0): _WeightNorm()\n          )\n        )\n      )\n      (padding): Wav2Vec2SamePadLayer()\n      (activation): GELUActivation()\n    )\n    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (layers): ModuleList(\n      (0-11): 12 x Wav2Vec2EncoderLayer(\n        (attention): Wav2Vec2SdpaAttention(\n          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.1, inplace=False)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (feed_forward): Wav2Vec2FeedForward(\n          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n          (output_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/380M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03f94445d59d41b99cc22c662d3c2f29"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"class GrammarDataset(Dataset):\n    def __init__(self, df, audio_dir, processor):\n        self.df = df\n        self.audio_dir = audio_dir\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        file_path = os.path.join(self.audio_dir, row['filename'])\n        try:\n            y, sr = librosa.load(file_path, sr=16000)\n        except:\n            y = np.zeros(16000 * 5)  # silent audio fallback\n\n        inputs = self.processor(y, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n        with torch.no_grad():\n            out = wav2vec(**{k: v.to(device) for k, v in inputs.items()})\n            x = out.last_hidden_state.mean(dim=1).squeeze(0).cpu()  # [768-dim]\n        y_score = torch.tensor(row['label'], dtype=torch.float32)\n        return x, y_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:06:13.556425Z","iopub.execute_input":"2025-05-02T19:06:13.556779Z","iopub.status.idle":"2025-05-02T19:06:13.563430Z","shell.execute_reply.started":"2025-05-02T19:06:13.556727Z","shell.execute_reply":"2025-05-02T19:06:13.562644Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"class GrammarRegressor(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(768, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 1)\n        )\n\n    def forward(self, x):\n        return self.net(x).squeeze(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:06:16.643450Z","iopub.execute_input":"2025-05-02T19:06:16.643743Z","iopub.status.idle":"2025-05-02T19:06:16.648704Z","shell.execute_reply.started":"2025-05-02T19:06:16.643720Z","shell.execute_reply":"2025-05-02T19:06:16.648062Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:06:19.766815Z","iopub.execute_input":"2025-05-02T19:06:19.767125Z","iopub.status.idle":"2025-05-02T19:06:19.773343Z","shell.execute_reply.started":"2025-05-02T19:06:19.767102Z","shell.execute_reply":"2025-05-02T19:06:19.772420Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"train_dataset = GrammarDataset(train_df, AUDIO_DIR, processor)\nval_dataset = GrammarDataset(val_df, AUDIO_DIR, processor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:06:20.415777Z","iopub.execute_input":"2025-05-02T19:06:20.416095Z","iopub.status.idle":"2025-05-02T19:06:20.421610Z","shell.execute_reply.started":"2025-05-02T19:06:20.416072Z","shell.execute_reply":"2025-05-02T19:06:20.420479Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:06:20.900506Z","iopub.execute_input":"2025-05-02T19:06:20.900823Z","iopub.status.idle":"2025-05-02T19:06:20.905400Z","shell.execute_reply.started":"2025-05-02T19:06:20.900799Z","shell.execute_reply":"2025-05-02T19:06:20.904675Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"model = GrammarRegressor().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\ncriterion = nn.MSELoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:06:22.550929Z","iopub.execute_input":"2025-05-02T19:06:22.551223Z","iopub.status.idle":"2025-05-02T19:06:22.562333Z","shell.execute_reply.started":"2025-05-02T19:06:22.551201Z","shell.execute_reply":"2025-05-02T19:06:22.561621Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"EPOCHS = 20\nfor epoch in range(EPOCHS):\n    model.train()\n    train_losses = []\n    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Training\"):\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        preds = model(x)\n        loss = criterion(preds, y)\n        loss.backward()\n        optimizer.step()\n        train_losses.append(loss.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T19:06:23.906623Z","iopub.execute_input":"2025-05-02T19:06:23.906910Z","iopub.status.idle":"2025-05-02T20:44:50.455411Z","shell.execute_reply.started":"2025-05-02T19:06:23.906888Z","shell.execute_reply":"2025-05-02T20:44:50.454789Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/20 - Training: 100%|██████████| 23/23 [04:57<00:00, 12.92s/it]\nEpoch 2/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.86s/it]\nEpoch 3/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.85s/it]\nEpoch 4/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.86s/it]\nEpoch 5/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.83s/it]\nEpoch 6/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.85s/it]\nEpoch 7/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.84s/it]\nEpoch 8/20 - Training: 100%|██████████| 23/23 [04:56<00:00, 12.87s/it]\nEpoch 9/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.84s/it]\nEpoch 10/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.84s/it]\nEpoch 11/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.84s/it]\nEpoch 12/20 - Training: 100%|██████████| 23/23 [04:54<00:00, 12.82s/it]\nEpoch 13/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.83s/it]\nEpoch 14/20 - Training: 100%|██████████| 23/23 [04:54<00:00, 12.80s/it]\nEpoch 15/20 - Training: 100%|██████████| 23/23 [04:54<00:00, 12.82s/it]\nEpoch 16/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.83s/it]\nEpoch 17/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.83s/it]\nEpoch 18/20 - Training: 100%|██████████| 23/23 [04:55<00:00, 12.83s/it]\nEpoch 19/20 - Training: 100%|██████████| 23/23 [04:54<00:00, 12.82s/it]\nEpoch 20/20 - Training: 100%|██████████| 23/23 [04:54<00:00, 12.82s/it]\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"    model.eval()\n    val_preds, val_labels = [], []\n    with torch.no_grad():\n        for x, y in tqdm(val_loader, desc=\"Validating\"):\n            x = x.to(device)\n            preds = model(x)\n            val_preds.extend(preds.cpu().numpy())\n            val_labels.extend(y.numpy())\n\n    rmse = mean_squared_error(val_labels, val_preds, squared=False)\n    print(f\"Epoch {epoch+1} - Train Loss: {np.mean(train_losses):.4f} - Val RMSE: {rmse:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T20:46:41.115402Z","iopub.execute_input":"2025-05-02T20:46:41.115697Z","iopub.status.idle":"2025-05-02T20:47:56.239271Z","shell.execute_reply.started":"2025-05-02T20:46:41.115665Z","shell.execute_reply":"2025-05-02T20:47:56.238340Z"}},"outputs":[{"name":"stderr","text":"Validating: 100%|██████████| 6/6 [01:15<00:00, 12.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 20 - Train Loss: 0.7508 - Val RMSE: 0.9599\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"full_dataset = GrammarDataset(df, AUDIO_DIR, processor)\nfull_loader = DataLoader(full_dataset, batch_size=16)\nall_preds, all_labels = [], []\nmodel.eval()\nwith torch.no_grad():\n    for x, y in tqdm(full_loader, desc=\"Evaluating Full Train Set\"):\n        x = x.to(device)\n        preds = model(x)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(y.numpy())\n\nrmse_final = mean_squared_error(all_labels, all_preds, squared=False)\nprint(f\"Final RMSE on Full Train Set: {rmse_final}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T21:04:55.962555Z","iopub.execute_input":"2025-05-02T21:04:55.963170Z","iopub.status.idle":"2025-05-02T21:11:05.907036Z","shell.execute_reply.started":"2025-05-02T21:04:55.963147Z","shell.execute_reply":"2025-05-02T21:11:05.906097Z"}},"outputs":[{"name":"stderr","text":"Evaluating Full Train Set: 100%|██████████| 28/28 [06:09<00:00, 13.21s/it]","output_type":"stream"},{"name":"stdout","text":"Final RMSE on Full Train Set: 0.8324033617973328\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": np.round(np.clip(test_preds, 0, 5)).astype(int)\n})\nsubmission.to_csv(\"submission_transformers_1.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T21:12:59.351653Z","iopub.execute_input":"2025-05-02T21:12:59.351935Z","iopub.status.idle":"2025-05-02T21:12:59.359360Z","shell.execute_reply.started":"2025-05-02T21:12:59.351914Z","shell.execute_reply":"2025-05-02T21:12:59.358795Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}